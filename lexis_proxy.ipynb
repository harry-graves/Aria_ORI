{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObsr2zVAfS9lc2ykR2CFmS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harry-graves/Aria_ORI/blob/main/lexis_proxy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LEXIS Proxy\n",
        "This notebook uses the conversion given in trajectory_conversion.ipynb to convert trajectories into the TUM file format, before sampling the poses by euclidean distance, and using this information to sample images taken along the trajectory at equal distances.\n",
        "\n",
        "These sampled images are ran through CLIP, with text prompts of several different room labels, such as office, kitchen, corridor etc. The room label with the highest probability according to CLIP is then written onto the image and saved for inspection."
      ],
      "metadata": {
        "id": "GKbq4GCP_lPi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting to TUM"
      ],
      "metadata": {
        "id": "6bnR4WOlAS55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# To convert OpenVINS trajectories (.txt) to .tum format\n",
        "\n",
        "def convert_ov_to_tum(input_file):\n",
        "    # Change the extension of the input file from .txt to .tum\n",
        "    output_file = os.path.splitext(input_file)[0] + '.tum'\n",
        "\n",
        "    with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
        "        first_line = True  # Flag to skip the header\n",
        "        for line in infile:\n",
        "            if first_line:\n",
        "                first_line = False  # Skip the first line (header)\n",
        "                continue\n",
        "\n",
        "            if line.startswith(\"#\") or not line.strip():\n",
        "                continue  # Skip comments and empty lines\n",
        "\n",
        "            data = line.strip().split()\n",
        "            timestamp = data[0]\n",
        "            # Extract quaternion and position components\n",
        "            q_x, q_y, q_z, q_w = data[1:5]  # Quaternion\n",
        "            p_x, p_y, p_z = map(float, data[5:8])  # Position\n",
        "\n",
        "            # Write in TUM format: timestamp, p_x, p_y, p_z, q_x, q_y, q_z, q_w\n",
        "            outfile.write(f\"{timestamp} {p_x} {p_y} {p_z} {q_x} {q_y} {q_z} {q_w}\\n\")\n",
        "\n",
        "\n",
        "# To convert Aria MPS trajectories (.csv) to .tum format\n",
        "\n",
        "def convert_mps_to_tum(input_file,loop=\"closed\"):\n",
        "    # Change the extension of the input file from .txt or .csv to .tum\n",
        "    output_file = os.path.splitext(input_file)[0] + '.tum'\n",
        "\n",
        "    with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
        "        first_line = True  # Flag to skip the header\n",
        "        for line in infile:\n",
        "            if first_line:\n",
        "                first_line = False  # Skip the first line (header)\n",
        "                continue\n",
        "\n",
        "            if not line.strip():\n",
        "                continue  # Skip empty lines\n",
        "\n",
        "            data = line.strip().split(',')\n",
        "\n",
        "            # The closed loop and open loop outputs have slightly differnet formats\n",
        "            # For open loop, the timestamp is in column 0, vs column 1 for closed loop\n",
        "            if loop == \"open\":\n",
        "                timestamp_us = float(data[0])  # tracking_timestamp_us\n",
        "            else:\n",
        "                timestamp_us = float(data[1])  # tracking_timestamp_us\n",
        "            # Convert microseconds to seconds for TUM format\n",
        "            timestamp_s = timestamp_us / 1e6\n",
        "\n",
        "            # Extract position components\n",
        "            p_x, p_y, p_z = map(float, data[3:6])  # Convert to float\n",
        "\n",
        "            # Extract quaternion components\n",
        "            q_x, q_y, q_z, q_w = data[6:10]\n",
        "\n",
        "            # Write in TUM format: timestamp, p_x, p_y, p_z, q_x, q_y, q_z, q_w\n",
        "            outfile.write(f\"{timestamp_s:.6f} {p_x} {p_y} {p_z} {q_x} {q_y} {q_z} {q_w}\\n\")\n",
        "\n",
        "\n",
        "# Usage\n",
        "input_filepath = 'ov_estimate.txt'\n",
        "convert_ov_to_tum(input_filepath)\n",
        "\n",
        "input_filepath = 'open_loop_trajectory.csv'\n",
        "convert_mps_to_tum(input_filepath,loop=\"open\")\n",
        "\n",
        "input_filepath = 'closed_loop_trajectory.csv'\n",
        "convert_mps_to_tum(input_filepath,loop=\"closed\")"
      ],
      "metadata": {
        "id": "cItGY0BB6qwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sampling images by distance"
      ],
      "metadata": {
        "id": "GUiNzc-ABJUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import re\n",
        "from shutil import copyfile\n",
        "\n",
        "def extract_timestamp_from_image_name(image_name):\n",
        "    \"\"\"\n",
        "    Extracts the timestamp from the image filename.\n",
        "    Assumes the format: image_builtin_interfaces.msg.Time(sec=<sec>, nanosec=<nanosec>).jpg\n",
        "    \"\"\"\n",
        "    match = re.search(r\"sec=(\\d+), nanosec=(\\d+)\", image_name)\n",
        "    if match:\n",
        "        sec = int(match.group(1))\n",
        "        nanosec = int(match.group(2))\n",
        "        timestamp_s = sec + nanosec / 1e9  # Convert to seconds\n",
        "        return timestamp_s\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def sample_images_by_distance(input_tum_file, images_dir, output_zipfile, sampling_distance=2.0):\n",
        "    \"\"\"\n",
        "    Sample images every 'sampling_distance' meters along the trajectory and zip the closest images.\n",
        "\n",
        "    input_tum_file: File containing the trajectory in TUM format.\n",
        "    images_dir: Directory containing the images.\n",
        "    output_zipfile: Name of the output zip file to store the sampled images.\n",
        "    sampling_distance: The distance interval in meters to sample images.\n",
        "    \"\"\"\n",
        "    with open(input_tum_file, 'r') as infile:\n",
        "        lines = infile.readlines()\n",
        "\n",
        "    sampled_timestamps = []\n",
        "    prev_position = None\n",
        "\n",
        "    for line in lines:\n",
        "        if not line.strip() or line.startswith(\"#\"):\n",
        "            continue\n",
        "\n",
        "        data = line.strip().split()\n",
        "        timestamp = float(data[0])\n",
        "        p_x, p_y, p_z = map(float, data[1:4])\n",
        "\n",
        "        current_position = np.array([p_x, p_y, p_z])\n",
        "\n",
        "        if prev_position is None:\n",
        "            sampled_timestamps.append(timestamp)\n",
        "            prev_position = current_position\n",
        "        else:\n",
        "            distance = np.linalg.norm(current_position - prev_position)\n",
        "\n",
        "            if distance >= sampling_distance:\n",
        "                sampled_timestamps.append(timestamp)\n",
        "                prev_position = current_position\n",
        "\n",
        "    # Parse all image filenames and extract their timestamps\n",
        "    image_files = os.listdir(images_dir)\n",
        "    image_timestamps = []\n",
        "    for image_file in image_files:\n",
        "        image_timestamp = extract_timestamp_from_image_name(image_file)\n",
        "        if image_timestamp is not None:\n",
        "            image_timestamps.append((image_timestamp, image_file))\n",
        "\n",
        "    # Sort images by their timestamp\n",
        "    image_timestamps.sort()\n",
        "\n",
        "    # Find the closest images to the sampled timestamps\n",
        "    selected_images = []\n",
        "    for sampled_ts in sampled_timestamps:\n",
        "        closest_image = min(image_timestamps, key=lambda x: abs(x[0] - sampled_ts))\n",
        "        selected_images.append(closest_image[1])\n",
        "\n",
        "    # Create a new zip file with the selected images\n",
        "    with zipfile.ZipFile(output_zipfile, 'w') as zipf:\n",
        "        for image_file in selected_images:\n",
        "            image_path = os.path.join(images_dir, image_file)\n",
        "            zipf.write(image_path, arcname=image_file)\n",
        "\n",
        "    print(f\"Sampled images have been zipped into {output_zipfile}\")\n",
        "\n",
        "# Usage example\n",
        "input_tum_file = 'closed_loop_trajectory.tum'\n",
        "images_dir = 'path/to/images'  # Directory where the images are stored\n",
        "output_zipfile = 'sampled_images.zip'\n",
        "sample_images_by_distance(input_tum_file, images_dir, output_zipfile, sampling_distance=2.0)\n"
      ],
      "metadata": {
        "id": "mySQiyixpMNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Room labels according to CLIP"
      ],
      "metadata": {
        "id": "v1WJXbXvBPko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import clip\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Load CLIP model\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
        "\n",
        "# Define the classes\n",
        "room_classes = [\"office\", \"corridor\", \"hallway\", \"staircase\", \"meeting room\", \"kitchen\"]\n",
        "text = clip.tokenize(room_classes).to(device)\n",
        "\n",
        "# Unzip the images from sampled_images.zip\n",
        "with zipfile.ZipFile('data/sampled_images.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('images_sampled')\n",
        "\n",
        "# Create a folder to store the labeled images\n",
        "output_folder = 'images_labelled'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Load a font with a larger size\n",
        "font_size = 48  # Increase the font size\n",
        "font = ImageFont.truetype(\"arial.ttf\", font_size)  # Replace with a valid font file path if necessary\n",
        "\n",
        "# Iterate through the images in the unzipped folder\n",
        "for image_name in os.listdir('images_sampled'):\n",
        "    image_path = os.path.join('images_sampled', image_name)\n",
        "    if image_path.endswith(\".jpg\"):\n",
        "        # Preprocess the image and pass it through the CLIP model\n",
        "        image = preprocess(Image.open(image_path)).unsqueeze(0).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            image_features = model.encode_image(image)\n",
        "            logits_per_image, _ = model(image, text)\n",
        "            probs = logits_per_image.softmax(dim=-1).cpu().numpy()[0]\n",
        "\n",
        "        # Find the label with the highest probability\n",
        "        max_prob_index = probs.argmax()\n",
        "        predicted_label = room_classes[max_prob_index]\n",
        "\n",
        "        # Load the original image\n",
        "        img = Image.open(image_path)\n",
        "        draw = ImageDraw.Draw(img)\n",
        "\n",
        "        # Determine the position to place the text (bottom-right corner)\n",
        "        text_size = draw.textsize(predicted_label, font=font)\n",
        "        image_width, image_height = img.size\n",
        "        text_position = (image_width - text_size[0] - 10, image_height - text_size[1] - 10)\n",
        "\n",
        "        # Add the predicted label to the image\n",
        "        draw.text(text_position, predicted_label, font=font, fill=\"white\")\n",
        "\n",
        "        # Save the labeled image to the output folder\n",
        "        labeled_image_path = os.path.join(output_folder, image_name)\n",
        "        img.save(labeled_image_path)\n",
        "\n",
        "print(f\"Labeled images saved to {output_folder}\")\n"
      ],
      "metadata": {
        "id": "72durF77BTrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils"
      ],
      "metadata": {
        "id": "-7YhFh_SBWVP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To clear all TUM files:\n",
        "\n",
        "# Specify the directory (current working directory)\n",
        "directory = '.'  # Current directory\n",
        "\n",
        "# Loop through all files in the directory\n",
        "for filename in os.listdir(directory):\n",
        "    # Check if the file ends with .tum\n",
        "    if filename.endswith('.tum'):\n",
        "        # Construct full file path\n",
        "        file_path = os.path.join(directory, filename)\n",
        "        # Delete the file\n",
        "        os.remove(file_path)\n",
        "        print(f\"Deleted: {file_path}\")"
      ],
      "metadata": {
        "id": "8ogyca3CZ1bs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}